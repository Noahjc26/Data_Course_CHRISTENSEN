---
title: "Assignment 9"
author: "Noah Christensen"
output: html_document
---
___


# Packages

Here I'm loading the packages I will use

```{r echo = TRUE, results = 'hide',message = FALSE}
library(tidyverse)
library(janitor)
library(GGally)
library(modelr)
library(easystats)
library(huxtable)
library(MASS)
```

___

# Reading in data

Let's load in the data and make sure the 1's and 0's read as TRUE and FALSE

```{r}
df <- read.csv("../../Data/GradSchool_Admissions.csv") %>% 
  janitor::clean_names()

df <- df %>% 
  mutate(admit = as.logical(admit))
```

___

# Pairs

I wanted to view pairs with a quick glance

```{r message=FALSE,warning=FALSE}
ggpairs(df)
```

___

# Plots

Let's view some quick plots

```{r}
df %>% 
  ggplot(aes(x=gre,y=admit)) +
  geom_boxplot() +
  facet_wrap(~rank) +
  theme_bw()

df %>% 
  ggplot(aes(x=gpa,y=admit)) +
  geom_boxplot() +
  facet_wrap(~rank) +
  theme_bw()

```

These plots show a distinct inclination towards higher gpa, higher gre, and a higher rank.

___

# Models

Now to create some models. I chose to make the first three super simple and only based on one variable. I made the fourth and fifth model a little more complicated.

```{r}
m1 <- glm(data = df,
          admit ~ gre,
          family = 'binomial')
m2 <- glm(data = df,
          admit ~ gpa,
          family = 'binomial')
m3 <- glm(data = df,
          admit ~ rank,
          family = 'binomial')
m4 <- glm(data = df,
          admit ~ gre + gpa + rank,
          family = 'binomial')
m5 <- glm(data = df,
          admit ~ gre * gpa * rank,
          family = 'binomial')
```

___

# Best model

Lets see what's the best model according to AIC values

```{r}
m6 <- glm(data = df,
          admit ~ .^2,
          family = 'binomial')

#feed largest most complicated model and it will find the best one
step <- stepAIC(m6)

#best simplified model for this data set
step$formula

bestmod <- glm(data = df,
          admit ~ gre + gpa + rank + gre:gpa,
          family = 'binomial')
```

___

# Comparison

Now for some comparison

```{r message=FALSE,warning=FALSE}
comparison <- compare_performance(m1,m2,m3,m4,m5,bestmod,rank=TRUE)
comparison
comparison %>% plot
```

```{r warning=FALSE}
huxreg(list("Model 1" = m1, "Model 2" = m2, "Model 3" = m3, "Model 4" = m4, "Model 5" = m5, "Best Model" = bestmod))
```

___

# Predictions

And finally to plot some predictions

```{r warning=FALSE, message=FALSE}

add_predictions(df,bestmod,type='response') %>% 
  ggplot(aes(x=gpa,y=pred,color=factor(rank))) +
  geom_smooth()

add_predictions(df,bestmod,type='response') %>% 
  ggplot(aes(x=gre,y=pred,color=factor(rank))) +
  geom_smooth()

add_predictions(df,bestmod,type='response') %>% 
  ggplot(aes(x=rank,y=pred)) +
  geom_smooth()

```

# Conclusions

It's insane how when modeling only rank, coming from a rank 4 means you only have a 10% change of being admitted, while you have a 30-40% higher chance just by coming from a Rank 1 school.

Having a gpa of 2.5 in a rank 1 school gives you better odds of getting accepted than having a 4.0 in a rank 4 school...

**Life is not fair** I guess is the conclusion haha.

